{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5e4aed7-a0b3-454a-9ba6-3b8412389f02",
   "metadata": {},
   "source": [
    "# **Implementing a basic CNN using PyTorch**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e80608-2576-4efc-ae3a-0238366f3c77",
   "metadata": {},
   "source": [
    "## **Import required packages**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "071fcab6-3d75-482f-945a-74c6fc7df864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "#pytorch utility imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "#neural net imports\n",
    "import torch.nn as nn, torch.nn.functional as F, torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "\n",
    "#import external libraries\n",
    "import pandas as pd,numpy as np,matplotlib.pyplot as plt, os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "%matplotlib inline\n",
    "\n",
    "#Set device to GPU or CPU based on availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31758c7-32a9-43c0-bf7f-7b678a7ebbcd",
   "metadata": {},
   "source": [
    "## **Load dataset into memory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f1a49d7-f587-4948-b6f1-5b9a369dcf6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "input_folder_path = \"input/data/MNIST/\"\n",
    "\n",
    "#The CSV contains a flat file of images, \n",
    "#i.e. each 28*28 image is flattened into a row of 784 colums \n",
    "#(1 column represents a pixel value)\n",
    "#For CNN, we would need to reshape this to our desired shape\n",
    "\n",
    "train_df = pd.read_csv(input_folder_path+\"train.csv\")\n",
    "\n",
    "#First column is the target/label\n",
    "train_labels = train_df['label'].values\n",
    "\n",
    "#Pixels values start from the 2nd column\n",
    "train_images = (train_df.iloc[:,1:].values).astype('float32')\n",
    "\n",
    "#Training and Validation Split\n",
    "train_images, val_images, train_labels, val_labels = train_test_split(\n",
    "train_images, train_labels, random_state=2020, test_size=0.2)\n",
    "\n",
    "#Here we reshape the flat row into [#images,#Channels,#Width,#Height]\n",
    "#Given this a simple grayscale image, we will have just 1 channel\n",
    "train_images = train_images.reshape(train_images.shape[0],1,28, 28)\n",
    "val_images = val_images.reshape(val_images.shape[0],1,28, 28)\n",
    "\n",
    "#Also, let's plot few samples\n",
    "for i in range(0, 6):\n",
    "    plt.subplot(160 + (i+1))\n",
    "    plt.imshow(train_images[i].reshape(28,28), cmap=plt.get_cmap('gray'))\n",
    "    plt.title(train_labels[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda749b9-04fd-4b06-9c3a-34ff891af99b",
   "metadata": {},
   "source": [
    "## **Normalize data and prepare train/val datasets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df0798b6-00f3-438b-9ab7-f0d1c914dbc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Labels Shape: torch.Size([33600])\n",
      "Train Images Shape: torch.Size([33600, 1, 28, 28])\n",
      "Validation Labels Shape: torch.Size([8400])\n",
      "Validation Images Shape: torch.Size([8400, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "#Covert Train Images from pandas/numpy to tensor and normalize the values\n",
    "train_images_tensor = torch.tensor(train_images)/255.0\n",
    "train_images_tensor = train_images_tensor.view(-1,1,28,28)\n",
    "train_labels_tensor = torch.tensor(train_labels)\n",
    "\n",
    "#Create a train TensorDataset\n",
    "train_tensor = TensorDataset(train_images_tensor, train_labels_tensor)\n",
    "\n",
    "#Covert Validation Images from pandas/numpy to tensor and normalize the values\n",
    "val_images_tensor = torch.tensor(val_images)/255.0\n",
    "val_images_tensor = val_images_tensor.view(-1,1,28,28)\n",
    "val_labels_tensor = torch.tensor(val_labels)\n",
    "\n",
    "#Create a Validation TensorDataset\n",
    "val_tensor = TensorDataset(val_images_tensor, val_labels_tensor)\n",
    "\n",
    "print(\"Train Labels Shape:\",train_labels_tensor.shape)\n",
    "print(\"Train Images Shape:\",train_images_tensor.shape)\n",
    "print(\"Validation Labels Shape:\",val_labels_tensor.shape)\n",
    "print(\"Validation Images Shape:\",val_images_tensor.shape)\n",
    "\n",
    "#Load Train and Validation TensorDatasets into the data generator for Training \n",
    "train_loader = DataLoader(train_tensor, batch_size=64\n",
    ", num_workers=2, shuffle=True)\n",
    "val_loader = DataLoader(val_tensor, batch_size=64, num_workers=2, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f44695-0789-4bf3-9872-9e7a0b29fd91",
   "metadata": {},
   "source": [
    "## **Define Convolutional Neural Network, function to train and predict**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c2c4a91-d681-484b-b624-1f771d2f4a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define conv-net\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        #First unit of convolution\n",
    "        self.conv_unit_1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        #Second unit of convolution        \n",
    "        self.conv_unit_2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "\n",
    "        #Fully connected layers\n",
    "        self.fc1 = nn.Linear(7*7*32, 128)       \n",
    "        self.fc2 = nn.Linear(128, 10)        \n",
    "    \n",
    "    #Connect the units\n",
    "    def forward(self, x):       \n",
    "        out = self.conv_unit_1(x)\n",
    "        out = self.conv_unit_2(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.fc1(out)\n",
    "        out = self.fc2(out)        \n",
    "        out = F.log_softmax(out,dim=1)                                \n",
    "        return out\n",
    "\n",
    "#Define Functions for Model Evaluation and generating Predictions    \n",
    "def make_predictions(data_loader):\n",
    "    #Explcitly set the model to eval mode\n",
    "    model.eval()\n",
    "    test_preds = torch.LongTensor()\n",
    "    actual = torch.LongTensor()\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "        output = model(data)\n",
    "\n",
    "        #Predict output/Take the index of the output with max value\n",
    "        preds = output.cpu().data.max(1, keepdim=True)[1]\n",
    "\n",
    "        #Combine tensors from each batch\n",
    "        test_preds = torch.cat((test_preds, preds), dim=0)\n",
    "        actual  = torch.cat((actual,target),dim=0)\n",
    "        \n",
    "    return actual,test_preds\n",
    "\n",
    "#Evalute model\n",
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:        \n",
    "        if torch.cuda.is_available():\n",
    "            data = data.cuda()\n",
    "            target = target.cuda()\n",
    "        output = model(data)\n",
    "        loss += F.cross_entropy(output, target, size_average=False).data.item()\n",
    "        predicted = output.data.max(1, keepdim=True)[1]   \n",
    "        correct += (target.reshape(-1,1) == predicted.reshape(-1,1)).float().sum()        \n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "        \n",
    "    print('\\nAverage Val Loss: {:.4f}, Val Accuracy: {}/{} ({:.3f}%)\\n'.format(\n",
    "        loss, correct, len(data_loader.dataset),\n",
    "        100. * correct / len(data_loader.dataset)))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87225197-a222-470f-b8a1-4d4adc678953",
   "metadata": {},
   "source": [
    "## **Create model instance, define Loss and optimizer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98cdee07-7887-46b6-975c-45ce4f665cc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv_unit_1): Sequential(\n",
      "    (0): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (conv_unit_2): Sequential(\n",
      "    (0): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU()\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (fc1): Linear(in_features=1568, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Create Model  instance\n",
    "model = ConvNet(10).to(device)\n",
    "\n",
    "#Define Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)    \n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6055c9d-3ffe-4f4b-b145-c18bd674d47d",
   "metadata": {},
   "source": [
    "## **Model training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72d7eb6f-cb2e-4642-afc2-73fcd6aecea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.0940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/_reduction.py:42: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Average Val Loss: 0.0792, Val Accuracy: 8165.0/8400 (97.202%)\n",
      "\n",
      "Epoch [2/5], Loss: 0.0349\n",
      "\n",
      "Average Val Loss: 0.0518, Val Accuracy: 8265.0/8400 (98.393%)\n",
      "\n",
      "Epoch [3/5], Loss: 0.0540\n",
      "\n",
      "Average Val Loss: 0.0515, Val Accuracy: 8262.0/8400 (98.357%)\n",
      "\n",
      "Epoch [4/5], Loss: 0.0047\n",
      "\n",
      "Average Val Loss: 0.0562, Val Accuracy: 8254.0/8400 (98.262%)\n",
      "\n",
      "Epoch [5/5], Loss: 0.0596\n",
      "\n",
      "Average Val Loss: 0.0568, Val Accuracy: 8271.0/8400 (98.464%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 5\n",
    "\n",
    "# Train the model\n",
    "total_step = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()        \n",
    "        \n",
    "    #After each epoch print Train loss and validation loss + accuracy\n",
    "    print ('Epoch [{}/{}], Loss: {:.4f}' .format(epoch+1, num_epochs, loss.item()))\n",
    "    evaluate(val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58773116-63e5-4a77-a3b5-9ea04d29d437",
   "metadata": {},
   "source": [
    "## **Make predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3b342f8c-4e75-456c-9073-d4a3841ccc3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy- 98.46000000000001\n",
      "\n",
      " Confusion Matrix\n",
      " [[810   0   2   1   0   0   2   0   1   1]\n",
      " [  1 925   2   1   0   0   0   2   2   1]\n",
      " [  0   0 830   2   1   0   0   0   0   0]\n",
      " [  0   1   7 858   0   2   0   1   0   2]\n",
      " [  1   0   0   0 851   0   0   0   1   2]\n",
      " [  0   0   2   6   0 724   3   0   2   0]\n",
      " [  1   0   1   1   0   0 798   0   1   0]\n",
      " [  0   1   7   0   4   0   0 875   2   3]\n",
      " [  3   4   7   3   3   2   5   0 805   2]\n",
      " [  0   0   0   0  20   1   0   7   2 795]]\n"
     ]
    }
   ],
   "source": [
    "#Make Predictions on Validation Dataset\n",
    "\n",
    "actual, predicted = make_predictions(val_loader)\n",
    "actual,predicted = np.array(actual).reshape(-1,1),np.array(predicted).reshape(-1,1)\n",
    "\n",
    "print(\"Validation Accuracy-\",round(accuracy_score(actual,predicted),4)*100)\n",
    "print(\"\\n Confusion Matrix\\n\",confusion_matrix(actual,predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Qiskit v0.34.2 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
